{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Medium Analytics\n",
    "##### by  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part 0: Check the robots.txt\n",
    "to see what you can scrape at: https://medium.com/robots.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Part 1: Sample - looking at a single page\n",
    "basic webpage accessing and scraping the top of the art topics page (without scrolling). Only about 10 articles. Was able to retrieve links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#the url topic (root url)\n",
    "url = \"https://medium.com/topic/art\"\n",
    "\n",
    "#requesting the url to get access to the page\n",
    "r = requests.get(url)\n",
    "#should be 200\n",
    "print(r)\n",
    "\n",
    "#parsing in the information\n",
    "soup = BeautifulSoup(r.content, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <script>\n",
      "   !function(c,f){var t,o,i,e=[],r={passive:!0,capture:!0},n=new Date,a=\"pointerup\",u=\"pointercancel\";function p(n,e){t||(t=e,o=n,i=new Date,w(f),s())}function s(){0<=o&&o<i-n&&(e.forEach(function(n){n(o,t)}),e=[])}function l(n){if(n.cancelable){var e=(1e12<n.timeStamp?new Date:performance.now())-n.timeStamp;\"pointerdown\"==n.type?function(n,e){function t(){p(n,e),i()}function o(){i()}function i(){f(a,t,r),f(u,o,r)}c(a,t,r),c(u,o,r)}(e,n):p(e,n)\n"
     ]
    }
   ],
   "source": [
    "#look at the html in nice format\n",
    "print(soup.prettify()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/@Rashmee/questions-still-linger-about-colonial-era-artefacts-18876e0e824?source=topic_page---------0------------------1',\n",
       " '/@Rashmee/questions-still-linger-about-colonial-era-artefacts-18876e0e824?source=topic_page---------0------------------1',\n",
       " '/@Rashmee/questions-still-linger-about-colonial-era-artefacts-18876e0e824?source=topic_page---------0------------------1',\n",
       " '/@Rashmee?source=topic_page---------0------------------1',\n",
       " '/@Rashmee/questions-still-linger-about-colonial-era-artefacts-18876e0e824?source=topic_page---------0------------------1',\n",
       " '/@chrisjones_32882/reading-art-paul-klees-twittering-machine-e36b88609c58?source=topic_page---------1------------------1',\n",
       " '/@chrisjones_32882/reading-art-paul-klees-twittering-machine-e36b88609c58?source=topic_page---------1------------------1',\n",
       " '/@chrisjones_32882/reading-art-paul-klees-twittering-machine-e36b88609c58?source=topic_page---------1------------------1',\n",
       " '/@chrisjones_32882?source=topic_page---------1------------------1',\n",
       " '/@chrisjones_32882/reading-art-paul-klees-twittering-machine-e36b88609c58?source=topic_page---------1------------------1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of link I want to get\n",
    "'<a href=\"https://psiloveyou.xyz/remembering-the-terrible-cb7ebf24a6da?source=topic_page---------6------------------1\"'\n",
    "\n",
    "#Regex pattern to get html tags (want entire html)\n",
    "#divs and labels were too confusing so this was the best/easiest way to get urls\n",
    "pattern = 'href=\"(.{5,100}source=topic_page\\-+\\d\\-+\\d)'\n",
    "\n",
    "#find all the htmls in the string using REGEX\n",
    "result = re.findall(pattern, str(soup))\n",
    "result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2: Using Selenium to Scroll and Get all the URLs at once \n",
    "creating a new browser that will automatically scroll down the page for you. Using the developer tools it was noticed that \"POST\" calls were being made when the scroll down occurred, but no \"GET\" calls were made. Thus, since we could not use the GET calls, we decided to use the scroller instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#opens a new browser to scroll down automatically\n",
    "browser = webdriver.Chrome(executable_path = r\"C:\\Users\\jesse\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "browser.get(\"https://medium.com/topic/politics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#code based off of stackoverflow code #4\n",
    "time.sleep(1)\n",
    "elem = browser.find_element_by_tag_name(\"body\")\n",
    "pagedowns = 100000\n",
    "while pagedowns:\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "    pagedowns-=1\n",
    "    \n",
    "pages = browser.page_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 3: Processing\n",
    "using the regex tested above, able to get html links from the browser object. Then dropping duplicates and clean the links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://gen.medium.com/does-cutting-u-s-aid-help-or-hurt-central-america-55db640f2add?source=topic_page---------5109------------------1',\n",
       " 'https://gen.medium.com/does-cutting-u-s-aid-help-or-hurt-central-america-55db640f2add?source=topic_page---------5109------------------1',\n",
       " '/@johnbwashington?source=topic_page---------5109------------------1',\n",
       " 'https://gen.medium.com/?source=topic_page---------5109------------------1',\n",
       " 'https://gen.medium.com/does-cutting-u-s-aid-help-or-hurt-central-america-55db640f2add?source=topic_page---------5109------------------1']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regex pattern to get html tags\n",
    "pattern = 'href=\"(.{5,100}source=topic_page\\-+\\d{1,5}\\-+\\d)'\n",
    "\n",
    "#get all the html links based on the pattern\n",
    "result = re.findall(pattern, pages)\n",
    "\n",
    "#put into a series to process\n",
    "html_links = pd.Series(result)\n",
    "\n",
    "#export to csv for safekeeping\n",
    "html_links.to_csv(\"htmls_politics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#using the saved csv\n",
    "topic = pd.read_csv(\"htmls_politics.csv\", index_col = 0, header = None)\n",
    "\n",
    "#drop all the duplicates\n",
    "htmls = topic.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    https://arcdigital.media/trumps-trade-war-is-k...\n",
       "1    /@maxburnswrites?source=topic_page---------0--...\n",
       "2    https://arcdigital.media/?source=topic_page---...\n",
       "3    /@fnfwriter?source=topic_page---------1-------...\n",
       "4    /politically-speaking?source=topic_page-------...\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a look at some of the htmls... seems as though some are missing the \"https:\"\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#just get the url column\n",
    "htmls = htmls[1]\n",
    "\n",
    "#there are some repeat html links, so getting rid of the repeats\n",
    "clean_htmls = htmls[~htmls.str.contains(r\"^.{2,30}\\?source=topic\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "### ADD HTTP to some versus not others ###\n",
    "\n",
    "#links with https already included (no user in url)\n",
    "with_http = clean_htmls[clean_htmls.str.contains(\"https://\")].reset_index(drop=True)\n",
    "\n",
    "#links without https:\n",
    "without_http = clean_htmls[~clean_htmls.str.contains(\"https://\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#adding medium before in order to get the full url\n",
    "urls = \"https://medium.com\" + without_http"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 1466)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see how many links\n",
    "len(with_http), len(without_http)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1679    https://magenta.as/legendary-cartoonist-ben-ka...\n",
       "1680    https://timeline.com/hannah-wilke-labial-art-9...\n",
       "1681    https://artplusmarketing.com/kathy-griffins-ar...\n",
       "1682    https://medium.muz.li/why-gradients-are-the-ne...\n",
       "1683    https://brightthemag.com/a-tale-of-two-artists...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine all the urls together\n",
    "pd.concat([urls, with_http], ignore_index = True).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#cleaned htmls (entire html should work)\n",
    "urls.to_csv(\"cleaned_htmls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Text Generator:\n",
    "example from: https://keras.io/examples/lstm_text_generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "money = pd.read_csv(\"./final_csvs/money.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = money[\"text\"].iloc[0].replace(\"[\", \"\").strip(\"[\").strip(\"]\").strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Potential ways to Save using a Free Library Card', 'Last year, I was contemplating to buy a premium subscription from one of the well-known investment research journals to improve my investment IQ. As they say, you get what you pay for; the cost of any good investment research subscription I was considering was at-least a couple of hundred dollars annually. Over lunch, I discussed this with a senior colleague whom I consider one of my mentors. He advised — “Why don’t you just go to a public library and get a free membership card, you don’t have to pay for any of this!”', 'That turned out to be one of the best advice I have ever received. Since then I have found multiple ways to save using my library membership card. I am sharing some of these tips here so that they can be used by the community. It is important to note that membership benefits for a library would vary depending on the community, patrons, etc. If you wish to save a trip to inquire about membership benefits, you can also visit your city library’s website or call them to inquire about member benefits', 'To get my library membership card, I went to my area’s library with an identity card and address proof, walked up to the front desk and had a membership card within minutes. Since then, every day I use my membership to read digital copies of The New York Times and Morning Star. I can also refer to Value Line’s investment research before purchasing or offloading stocks. Though my library doesn’t, I know some libraries also offer members access to The Wall Street Journal. These subscriptions have enabled me in my pursuit and helped save a few hundred dollars over the past year', 'Hoopla is a digital platform on which I borrow movies, TV series, music, audiobooks, etc free of cost using my library card. Hoopla allows up to five borrows every month. I generally use Hoopla to listen to audiobooks. Occasionally, I also borrow movies or television series', 'For those who like to watch movies — Kanopy is an on-demand streaming video platform that can be availed with participating library’s membership card. I have not explored this option much since I don’t watch movies as much but for people who would like to explore this option, here is a link to create an account. You can check if you are a member of a participating library and choose to enjoy the services', 'Most Libraries also have an enviable in-house collection of movies and music for members too. I have been able to witness some of the greatest classics in this collection which I have struggled to find elsewhere', 'I use Libby by Overdrive to borrow ebooks from the library for my monthly consumption. If you are in the US, you can also use Libby to read books in the Kindle app too. For learning new skills or enhancing old ones via online courses, I use websites like Lynda.com which is included in library’s membership benefits', 'There are several other resources that a library membership may provide which I have not used yet but might be useful. Some of them are —, Looking back, I have been able to save money on subscriptions for the resources I have discussed and utilized it elsewhere. I firmly believe — “a penny saved is a penny earned”. Through this article, I am hoping more people would take that one trip to their area’s public library\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = dict(enumerate(text))\n",
    "character_indices = dict((i,y) for y,i in enumerate(sorted(set(text))))\n",
    "indices = dict((y,i) for y,i in enumerate(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " \"'\": 2,\n",
       " ',': 3,\n",
       " '-': 4,\n",
       " '.': 5,\n",
       " ';': 6,\n",
       " 'A': 7,\n",
       " 'C': 8,\n",
       " 'F': 9,\n",
       " 'H': 10,\n",
       " 'I': 11,\n",
       " 'J': 12,\n",
       " 'K': 13,\n",
       " 'L': 14,\n",
       " 'M': 15,\n",
       " 'N': 16,\n",
       " 'O': 17,\n",
       " 'P': 18,\n",
       " 'Q': 19,\n",
       " 'S': 20,\n",
       " 'T': 21,\n",
       " 'U': 22,\n",
       " 'V': 23,\n",
       " 'W': 24,\n",
       " 'Y': 25,\n",
       " 'a': 26,\n",
       " 'b': 27,\n",
       " 'c': 28,\n",
       " 'd': 29,\n",
       " 'e': 30,\n",
       " 'f': 31,\n",
       " 'g': 32,\n",
       " 'h': 33,\n",
       " 'i': 34,\n",
       " 'j': 35,\n",
       " 'k': 36,\n",
       " 'l': 37,\n",
       " 'm': 38,\n",
       " 'n': 39,\n",
       " 'o': 40,\n",
       " 'p': 41,\n",
       " 'q': 42,\n",
       " 'r': 43,\n",
       " 's': 44,\n",
       " 't': 45,\n",
       " 'u': 46,\n",
       " 'v': 47,\n",
       " 'w': 48,\n",
       " 'x': 49,\n",
       " 'y': 50,\n",
       " 'z': 51,\n",
       " '—': 52,\n",
       " '’': 53,\n",
       " '“': 54,\n",
       " '”': 55}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 50\n",
    "step = 4\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - max_length, step):\n",
    "    sentences.append(text[i:i + max_length])\n",
    "    next_chars.append(text[i + max_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorization \n",
    "X = np.zeros((len(sentences), max_length, len(text)))\n",
    "Y = np.zeros((len(sentences), len(text)))\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i,t, character_indices[char]] = 1\n",
    "    Y[i, character_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8d1aceb11484>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape = (max_length, len(text))))\n",
    "model.add(Dense(len(text), activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch LSTM model example:\n",
    "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

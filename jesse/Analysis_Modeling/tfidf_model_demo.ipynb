{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfidf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics = pd.read_csv(\"./final_csvs/politics.csv\", index_col = 0)\n",
    "money = pd.read_csv(\"./final_csvs/money.csv\", index_col = 0)\n",
    "sports = pd.read_csv(\"./final_csvs/sports.csv\", index_col = 0)\n",
    "tech = pd.read_csv(\"./final_csvs/tech.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there was a bug with the webscraping: people with 2020 claps have the wrong number of claps. \n",
    "#checked via website, having differing number of claps\n",
    "politics = politics[politics.claps != 2020]\n",
    "\n",
    "#get ratio of clap to followers, put as a new feature\n",
    "clap_ratio = politics.claps / politics.followers\n",
    "\n",
    "#get number of followers:\n",
    "followers = politics.followers\n",
    "\n",
    "#put the clap ratio as a new feature\n",
    "politics[\"clap_ratio\"] = clap_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>username</th>\n",
       "      <th>user_since</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>published</th>\n",
       "      <th>claps</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>clap_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://medium.com/@lizardgrey/lets-pass-on-th...</td>\n",
       "      <td>Let’s Pass on the Pizzazz, NBC, and Listen to ...</td>\n",
       "      <td>Elizabeth Grey</td>\n",
       "      <td>medium.com/@lizardgrey</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Nov 14</td>\n",
       "      <td>22</td>\n",
       "      <td>['[Photo courtesy of Pixabay, There is a diffe...</td>\n",
       "      <td>['Politics', 'Impeachment', 'Ukraine', 'Diplom...</td>\n",
       "      <td>0.385965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://medium.com/swlh/politics-isnt-my-passi...</td>\n",
       "      <td>Politics Isn’t My Passion</td>\n",
       "      <td>Elizabeth Grey</td>\n",
       "      <td>medium.com/@lizardgrey</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Nov 12</td>\n",
       "      <td>103</td>\n",
       "      <td>['[image courtesy of Pixabay, Last night I was...</td>\n",
       "      <td>['Top ', 'Story', 'Submit, ', 'Politics', 'Tru...</td>\n",
       "      <td>1.807018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://medium.com/@lizardgrey/my-no-lies-diet...</td>\n",
       "      <td>The No More Lies Diet Book</td>\n",
       "      <td>Elizabeth Grey</td>\n",
       "      <td>medium.com/@lizardgrey</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Nov 10</td>\n",
       "      <td>2</td>\n",
       "      <td>['[I can’t write about politics today. It’s to...</td>\n",
       "      <td>['Weight ', 'Loss', 'Self ', 'Improvement', 'E...</td>\n",
       "      <td>0.035088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://medium.com/the-slowdown/how-likely-is-...</td>\n",
       "      <td>How Likely is a Real-life Terminator?</td>\n",
       "      <td>Amie Haven</td>\n",
       "      <td>medium.com/@amiehaven</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Nov 14</td>\n",
       "      <td>104</td>\n",
       "      <td>['[Lethal autonomous weapon systems (LAWS) are...</td>\n",
       "      <td>['About', 'Pitch ', 'Us ', 'Slalom, ', 'Artifi...</td>\n",
       "      <td>4.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://medium.com/@lizardgrey/lets-pass-on-th...</td>\n",
       "      <td>Let’s Pass on the Pizzazz, NBC, and Listen to ...</td>\n",
       "      <td>Elizabeth Grey</td>\n",
       "      <td>medium.com/@lizardgrey</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Nov 14</td>\n",
       "      <td>22</td>\n",
       "      <td>['[Photo courtesy of Pixabay, There is a diffe...</td>\n",
       "      <td>['Politics', 'Impeachment', 'Ukraine', 'Diplom...</td>\n",
       "      <td>0.385965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://medium.com/@lizardgrey/lets-pass-on-th...   \n",
       "1  https://medium.com/swlh/politics-isnt-my-passi...   \n",
       "2  https://medium.com/@lizardgrey/my-no-lies-diet...   \n",
       "3  https://medium.com/the-slowdown/how-likely-is-...   \n",
       "4  https://medium.com/@lizardgrey/lets-pass-on-th...   \n",
       "\n",
       "                                               title          author  \\\n",
       "0  Let’s Pass on the Pizzazz, NBC, and Listen to ...  Elizabeth Grey   \n",
       "1                          Politics Isn’t My Passion  Elizabeth Grey   \n",
       "2                         The No More Lies Diet Book  Elizabeth Grey   \n",
       "3              How Likely is a Real-life Terminator?      Amie Haven   \n",
       "4  Let’s Pass on the Pizzazz, NBC, and Listen to ...  Elizabeth Grey   \n",
       "\n",
       "                 username  user_since  following  followers published  claps  \\\n",
       "0  medium.com/@lizardgrey      2019.0       82.0       57.0    Nov 14     22   \n",
       "1  medium.com/@lizardgrey      2019.0       82.0       57.0    Nov 12    103   \n",
       "2  medium.com/@lizardgrey      2019.0       82.0       57.0    Nov 10      2   \n",
       "3   medium.com/@amiehaven      2019.0       17.0       21.0    Nov 14    104   \n",
       "4  medium.com/@lizardgrey      2019.0       82.0       57.0    Nov 14     22   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['[Photo courtesy of Pixabay, There is a diffe...   \n",
       "1  ['[image courtesy of Pixabay, Last night I was...   \n",
       "2  ['[I can’t write about politics today. It’s to...   \n",
       "3  ['[Lethal autonomous weapon systems (LAWS) are...   \n",
       "4  ['[Photo courtesy of Pixabay, There is a diffe...   \n",
       "\n",
       "                                                tags  clap_ratio  \n",
       "0  ['Politics', 'Impeachment', 'Ukraine', 'Diplom...    0.385965  \n",
       "1  ['Top ', 'Story', 'Submit, ', 'Politics', 'Tru...    1.807018  \n",
       "2  ['Weight ', 'Loss', 'Self ', 'Improvement', 'E...    0.035088  \n",
       "3  ['About', 'Pitch ', 'Us ', 'Slalom, ', 'Artifi...    4.952381  \n",
       "4  ['Politics', 'Impeachment', 'Ukraine', 'Diplom...    0.385965  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to do a bit of preprocessing first! \n",
    "#remove pixabay\n",
    "\n",
    "#politics data\n",
    "str1 = politics.text.iloc[:10]\n",
    "\n",
    "#money data \n",
    "str2 = money.text.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['[Photo courtesy of Pixabay, There is a diffe...\n",
       "1    ['[image courtesy of Pixabay, Last night I was...\n",
       "2    ['[I can’t write about politics today. It’s to...\n",
       "3    ['[Lethal autonomous weapon systems (LAWS) are...\n",
       "4    ['[Photo courtesy of Pixabay, There is a diffe...\n",
       "5    ['[What the first day of the House’s public he...\n",
       "6    ['[To the best of my knowledge, nobody out the...\n",
       "7    ['[A New York judge ordered on Thursday that P...\n",
       "8    ['[Bill Gates joined the list of billionaires ...\n",
       "9    ['[Let’s talk about guns', 'My children had a ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_str = pd.concat([str1,str2]).reset_index(drop=True)\n",
    "all_str.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['account', 'air', 'apple', 'bubble', 'bubbles', 'card', 'companies', 'company', 'credit', 'day', 'did', 'gates', 'human', 'ico', 'investment', 'investors', 'just', 'know', 'laws', 'like', 'make', 'market', 'money', 'month', 'new', 'news', 'people', 'plan', 'portfolio', 'president', 'price', 'public', 'retirement', 'right', 'said', 'save', 'say', 'sea', 'south', 'stock', 'stocks', 'time', 'tronics', 'trump', 'try', 'want', 'way', 'write', 'year', 'years']\n"
     ]
    }
   ],
   "source": [
    "#create the vector\n",
    "#focus on max_features as well\n",
    "vector = tfidf(stop_words = \"english\", strip_accents = 'ascii', max_features = 50)\n",
    "\n",
    "#fit the data\n",
    "vector.fit(all_str)\n",
    "\n",
    "#can look at the vectorizer\n",
    "print(vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the data, aka manipulating it based on the weights we \n",
    "#determined before by fitting our data \n",
    "train = vector.transform(all_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20x50 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 283 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y = [0] * 10 + [1] * 10\n",
    "train_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### when do we do train test split ?\n",
    "\n",
    "-when we want to predict something we've never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the test set\n",
    "test1 = politics.text.iloc[10:15]\n",
    "test2 = money.text.iloc[10:15]\n",
    "#test1\n",
    "test_set = pd.concat([test1, test2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#still need to preprocess (in string form)\n",
    "test_trans = vector.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x50 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 135 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need Y (aka labels since this is supervised)\n",
    "\n",
    "test_Y = [0] * 5 + [1] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model (look at the documentation to see if there's any \n",
    "# parameters) you should pay closer attention to.\n",
    "\n",
    "#this is how you create a basic decision tree\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "#fit the model, use your train data\n",
    "dt.fit(train, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(test_trans, test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = pd.read_csv(\"/Users/jennayang/Documents/Medium Project Data/medium-tech-data.csv\")\n",
    "tech.drop(tech.columns[[0, 10, 11]], axis = 1, inplace = True)\n",
    "tech = tech[tech.tags != '[]']  #drop rows that have no tags\n",
    "tech = tech.dropna() #drop empty rows\n",
    "tech.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_content = tech.text[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code from https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to store word frequencies in dictionary while removing stop words\n",
    "\n",
    "def _create_dictionary_table(text_string) -> dict:\n",
    "   \n",
    "    # Removing stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    words = word_tokenize(text_string)\n",
    "    \n",
    "    # Reducing words to their root form\n",
    "    stem = PorterStemmer()\n",
    "    \n",
    "    # Creating dictionary for the word frequency table\n",
    "    frequency_table = dict()\n",
    "    for wd in words:\n",
    "        wd = stem.stem(wd)\n",
    "        if wd in stop_words:\n",
    "            continue\n",
    "        if wd in frequency_table:\n",
    "            frequency_table[wd] += 1\n",
    "        else:\n",
    "            frequency_table[wd] = 1\n",
    "\n",
    "    return frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(article) #split and store article content into set of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to score each sentence by its words and their frequencies\n",
    "\n",
    "def _calculate_sentence_scores(sentences, frequency_table) -> dict:   \n",
    "\n",
    "    # Algorithm for scoring a sentence by its words\n",
    "    sentence_weight = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_wordcount = (len(word_tokenize(sentence)))\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "        for word_weight in frequency_table:\n",
    "            if word_weight in sentence.lower():\n",
    "                sentence_wordcount_without_stop_words += 1\n",
    "                if sentence[:7] in sentence_weight:\n",
    "                    sentence_weight[sentence[:7]] += frequency_table[word_weight]\n",
    "                else:\n",
    "                    sentence_weight[sentence[:7]] = frequency_table[word_weight]\n",
    "\n",
    "        sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] / sentence_wordcount_without_stop_words\n",
    "      \n",
    "    return sentence_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the average score of a sentence\n",
    "\n",
    "def _calculate_average_score(sentence_weight) -> int:\n",
    "   \n",
    "    # Calculating the average score for the sentences\n",
    "    sum_values = 0\n",
    "    for entry in sentence_weight:\n",
    "        sum_values += sentence_weight[entry]\n",
    "\n",
    "    # Getting sentence average value from source text\n",
    "    average_score = (sum_values / len(sentence_weight))\n",
    "\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the article summary \n",
    "\n",
    "def _get_article_summary(sentences, sentence_weight, threshold):\n",
    "    sentence_counter = 0\n",
    "    article_summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] >= (threshold):\n",
    "            article_summary += \" \" + sentence\n",
    "            sentence_counter += 1\n",
    "\n",
    "    return article_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run article summary \n",
    "\n",
    "def _run_article_summary(article):\n",
    "    \n",
    "    #creating a dictionary for the word frequency table\n",
    "    frequency_table = _create_dictionary_table(article)\n",
    "\n",
    "    #tokenizing the sentences\n",
    "    sentences = sent_tokenize(article)\n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_scores = _calculate_sentence_scores(sentences, frequency_table)\n",
    "\n",
    "    #getting the threshold\n",
    "    threshold = _calculate_average_score(sentence_scores)\n",
    "\n",
    "    #producing the summary\n",
    "    article_summary = _get_article_summary(sentences, sentence_scores, 1.5 * threshold)\n",
    "\n",
    "    return article_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Not writing or posting, but the raw, mechanical act of typing. Typing, unsurprisingly, is not violent enough to cause such trauma to the body. Typing, explains Johnson, is one of the easiest things we can do. “It’s not a whole heck of a lot of effort,” says Johnson. Whether we’re typing or not, eventually we all must die.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    summary_results = run_article_summary(article_content)\n",
    "    print(summary_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

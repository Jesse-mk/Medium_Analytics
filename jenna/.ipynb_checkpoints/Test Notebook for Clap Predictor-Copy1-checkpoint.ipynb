{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "1. https://minimaxir.com/2017/06/reddit-deep-learning/ \n",
    "2. https://www.freecodecamp.org/news/how-to-predict-likes-and-shares-based-on-your-articles-title-using-machine-learning-47f98f0612ea/\n",
    "3. https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-4-count-vectorizer-b3f4944e51b5\n",
    "\n",
    "Notes: need more feature engineering (scrape or add data), also need to clean data for special characters, etc...\n",
    "\n",
    "Problems: dealing with text data, model doesnt work at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfidf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = pd.read_csv(r\"C:\\Users\\Jenna\\Documents\\medium-tech-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = tech.drop(tech.columns[[0, 10, 11]], axis = 1) #drop null columns\n",
    "tech = tech.drop(['url', 'username'], axis = 1) #drop unused columns (for now)\n",
    "tech = tech[~(tech.text == '[]')]\n",
    "tech = tech.dropna() #drop null rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity purposes for now,\n",
    "I will just look at the text column. Will add more later\n",
    "\n",
    "(probably need to scrape/add more features such as follower data, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claps</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>The agricultural food production mechanisms an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>After many years of overdone bass and lacklust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>Welcome to Bad Ideas, a column in which we exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>197</td>\n",
       "      <td>Welcome to Bad Ideas, a column in which we exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>827</td>\n",
       "      <td>Welcome to Bad Ideas, a column in which we exa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  claps                                               text\n",
       "0   155  The agricultural food production mechanisms an...\n",
       "1    83  After many years of overdone bass and lacklust...\n",
       "2   197  Welcome to Bad Ideas, a column in which we exa...\n",
       "3   197  Welcome to Bad Ideas, a column in which we exa...\n",
       "4   827  Welcome to Bad Ideas, a column in which we exa..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech2 = tech[['claps', 'text']]\n",
    "tech2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jenna\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# cleaning - making all claps into integer value\n",
    "\n",
    "def convert_to_number(x):\n",
    "    total_stars = 0\n",
    "    if 'K' in x:\n",
    "        if len(x) > 1:\n",
    "            total_stars = float(x.replace('K', '')) * 1000 # convert k to a thousand\n",
    "    else:\n",
    "        try:\n",
    "            total_stars = int(x) # Less than 1000\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return int(total_stars)\n",
    "\n",
    "tech2['claps'] = tech2['claps'].apply(convert_to_number)\n",
    "tech2 = tech2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training, validation, test (60/20/20)\n",
    "x = tech2.text\n",
    "y = tech2.claps\n",
    "SEED = 2000\n",
    "\n",
    "#split train and val/test\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.4, random_state=SEED)\n",
    "#split val and test\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize text\n",
    "tvec = tfidf(max_features = 100000)\n",
    "x_train_tfidf = tvec.fit_transform(x_train)\n",
    "x_validation_tfidf = tvec.transform(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check: do we need to normalize data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "75/74 [==============================] - 2s 27ms/step - loss: 7765097.9024 - accuracy: 0.0054 - val_loss: 3010785.3504 - val_accuracy: 0.0063\n",
      "Epoch 2/5\n",
      "75/74 [==============================] - 2s 22ms/step - loss: 7740360.6374 - accuracy: 0.0033 - val_loss: 2985714.7882 - val_accuracy: 0.0025\n",
      "Epoch 3/5\n",
      "75/74 [==============================] - 1s 20ms/step - loss: 7710827.4692 - accuracy: 0.0025 - val_loss: 2942573.0236 - val_accuracy: 0.0025\n",
      "Epoch 4/5\n",
      "75/74 [==============================] - 1s 20ms/step - loss: 7636372.5715 - accuracy: 0.0021 - val_loss: 2883547.7967 - val_accuracy: 0.0013\n",
      "Epoch 5/5\n",
      "75/74 [==============================] - 2s 20ms/step - loss: 7562863.7999 - accuracy: 8.3438e-04 - val_loss: 2820065.8671 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22e21e706c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model building - needs work\n",
    "def batch_generator_shuffle(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    np.random.shuffle(index)\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:].toarray()\n",
    "        y_batch = y_data[y_data.index[index_batch]]\n",
    "        counter += 1\n",
    "        yield X_batch,y_batch\n",
    "        if (counter > number_of_batches):\n",
    "            np.random.shuffle(index)\n",
    "            counter=0\n",
    "            \n",
    "model_s = Sequential()\n",
    "model_s.add(Dense(64, activation='relu', input_dim=20676))\n",
    "model_s.add(Dense(64, activation='relu'))\n",
    "model_s.add(Dense(1))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "model_s.compile(optimizer=optimizer,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_s.fit_generator(generator=batch_generator_shuffle(x_train_tfidf, y_train, 32),\n",
    "                    epochs=5, validation_data=(x_validation_tfidf, y_validation),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[205.0973 ],\n",
       "       [156.43466],\n",
       "       [201.00728],\n",
       "       [193.64778],\n",
       "       [166.66046],\n",
       "       [156.98335],\n",
       "       [314.93533],\n",
       "       [202.71512],\n",
       "       [239.74243],\n",
       "       [196.07767]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = x_train_tfidf[:10]\n",
    "example_result = model_s.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
